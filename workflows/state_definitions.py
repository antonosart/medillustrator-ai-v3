"""
MedIllustrator-AI v3.0 - Expert-Level State Definitions
Enhanced state management Î¼Îµ comprehensive typing ÎºÎ±Î¹ validation improvements

EXPERT IMPROVEMENTS APPLIED:
- âœ… Magic numbers elimination with Validation Constants
- âœ… Function complexity reduction with extracted methods
- âœ… Duplicate validation pattern elimination
- âœ… Enhanced type safety with proper TypedDict usage
- âœ… Comprehensive validation with specific error handling
- âœ… Performance optimization with cached validation

Author: Andreas Antonos
Date: 2025-07-18
"""

from typing import Dict, List, Any, Optional, TypedDict, NotRequired, Union, Callable
from dataclasses import dataclass, field
from datetime import datetime
from enum import Enum, IntEnum
from pathlib import Path
import uuid
import logging
from functools import wraps

logger = logging.getLogger(__name__)


# ============================================================================
# EXPERT IMPROVEMENT 1: VALIDATION CONSTANTS (Magic Numbers Elimination)
# ============================================================================


class ValidationConstants:
    """Centralized validation constants - Expert improvement Î³Î¹Î± magic numbers elimination"""

    # Image validation constants
    MIN_IMAGE_SIZE_PIXELS = 100
    MAX_ASPECT_RATIO = 10.0
    MIN_ASPECT_RATIO = 0.1
    MAX_IMAGE_DIMENSIONS = (5000, 5000)
    MIN_IMAGE_DIMENSIONS = (50, 50)

    # Quality assessment constants
    HIGH_CONFIDENCE_THRESHOLD = 0.8
    MEDIUM_CONFIDENCE_THRESHOLD = 0.7
    LOW_CONFIDENCE_THRESHOLD = 0.5
    MINIMUM_ACCEPTABLE_CONFIDENCE = 0.4

    # Performance constants
    MAX_PROCESSING_TIME_SECONDS = 300.0
    WARNING_PROCESSING_TIME_SECONDS = 30.0
    MEMORY_WARNING_THRESHOLD_MB = 1024.0
    MEMORY_CRITICAL_THRESHOLD_MB = 2048.0

    # Agent-specific constants
    MIN_MEDICAL_TERMS_COUNT = 1
    MAX_MEDICAL_TERMS_COUNT = 50
    MIN_TEXT_LENGTH_CHARACTERS = 10
    MAX_TEXT_LENGTH_CHARACTERS = 10000

    # Bloom taxonomy constants
    BLOOM_LEVEL_COUNT = 6
    MIN_BLOOM_SCORE = 0.0
    MAX_BLOOM_SCORE = 1.0

    # Cognitive load constants
    MIN_COGNITIVE_LOAD = 0.0
    MAX_COGNITIVE_LOAD = 10.0
    OPTIMAL_COGNITIVE_LOAD_MIN = 3.0
    OPTIMAL_COGNITIVE_LOAD_MAX = 7.0

    # Accessibility constants
    MIN_ACCESSIBILITY_SCORE = 0.0
    MAX_ACCESSIBILITY_SCORE = 1.0
    WCAG_AA_THRESHOLD = 0.7
    WCAG_AAA_THRESHOLD = 0.9

    # State validation constants
    MAX_ERROR_COUNT = 10
    MAX_WARNING_COUNT = 20
    MIN_SESSION_ID_LENGTH = 8
    MAX_SESSION_ID_LENGTH = 64


class QualityMetrics:
    """Quality assessment metrics constants"""

    EXCEPTIONAL_QUALITY_MIN = 0.9
    GOOD_QUALITY_MIN = 0.8
    SATISFACTORY_QUALITY_MIN = 0.6
    POOR_QUALITY_MAX = 0.4

    TERM_COUNT_EXCELLENT = 15
    TERM_COUNT_GOOD = 10
    TERM_COUNT_SATISFACTORY = 5

    PROCESSING_TIME_EXCELLENT = 10.0
    PROCESSING_TIME_GOOD = 20.0
    PROCESSING_TIME_ACCEPTABLE = 30.0


# ============================================================================
# EXPERT IMPROVEMENT 2: ENHANCED ENUMS WITH VALIDATION
# ============================================================================


class AssessmentStage(Enum):
    """Assessment workflow stages Î¼Îµ proper ordering"""

    INITIALIZATION = "initialization"
    PREPROCESSING = "preprocessing"
    FEATURE_EXTRACTION = "feature_extraction"
    MEDICAL_TERMS = "medical_terms"
    BLOOM_TAXONOMY = "bloom_taxonomy"
    COGNITIVE_LOAD = "cognitive_load"
    ACCESSIBILITY = "accessibility"
    VISUAL_ANALYSIS = "visual_analysis"
    PARALLEL_AGENTS = "parallel_agents"
    VALIDATION = "validation"
    SYNTHESIS = "synthesis"
    FINALIZATION = "finalization"
    COMPLETED = "completed"
    ERROR = "error"

    @classmethod
    def get_ordered_stages(cls) -> List["AssessmentStage"]:
        """Get stages in proper execution order"""
        return [
            cls.INITIALIZATION,
            cls.PREPROCESSING,
            cls.FEATURE_EXTRACTION,
            cls.MEDICAL_TERMS,
            cls.BLOOM_TAXONOMY,
            cls.COGNITIVE_LOAD,
            cls.ACCESSIBILITY,
            cls.VISUAL_ANALYSIS,
            cls.PARALLEL_AGENTS,
            cls.VALIDATION,
            cls.SYNTHESIS,
            cls.FINALIZATION,
            cls.COMPLETED,
        ]

    def get_progress_percentage(self) -> float:
        """Get workflow progress percentage Î³Î¹Î± this stage"""
        ordered_stages = self.get_ordered_stages()
        if self == self.ERROR:
            return 0.0
        if self == self.COMPLETED:
            return 100.0

        try:
            stage_index = ordered_stages.index(self)
            return (stage_index / len(ordered_stages)) * 100.0
        except ValueError:
            return 0.0


class AgentStatus(Enum):
    """Agent execution status Î¼Îµ comprehensive tracking"""

    PENDING = "pending"
    RUNNING = "running"
    COMPLETED = "completed"
    FAILED = "failed"
    TIMEOUT = "timeout"
    CANCELLED = "cancelled"
    RETRYING = "retrying"

    def is_terminal(self) -> bool:
        """Check if status is terminal (no further processing)"""
        return self in [self.COMPLETED, self.FAILED, self.CANCELLED]

    def is_active(self) -> bool:
        """Check if agent is actively processing"""
        return self in [self.RUNNING, self.RETRYING]


class ErrorSeverity(IntEnum):
    """Error severity levels Î¼Îµ proper ordering"""

    LOW = 1
    MEDIUM = 2
    HIGH = 3
    CRITICAL = 4

    def get_color_code(self) -> str:
        """Get color code Î³Î¹Î± UI display"""
        color_map = {
            self.LOW: "#28a745",  # Green
            self.MEDIUM: "#ffc107",  # Yellow
            self.HIGH: "#fd7e14",  # Orange
            self.CRITICAL: "#dc3545",  # Red
        }
        return color_map[self]


class QualityFlag(Enum):
    """Quality assessment flags Î¼Îµ specific meanings"""

    EXCEPTIONAL_QUALITY = "exceptional_quality"
    GOOD_QUALITY = "good_quality"
    SATISFACTORY_QUALITY = "satisfactory_quality"
    POOR_QUALITY = "poor_quality"
    LOW_CONFIDENCE = "low_confidence"
    HIGH_COGNITIVE_LOAD = "high_cognitive_load"
    ACCESSIBILITY_ISSUES = "accessibility_issues"
    REQUIRES_HUMAN_REVIEW = "requires_human_review"
    PROCESSING_TIMEOUT = "processing_timeout"
    PERFORMANCE_WARNING = "performance_warning"

    def get_priority_level(self) -> int:
        """Get priority level Î³Î¹Î± flag ordering"""
        priority_map = {
            self.POOR_QUALITY: 5,
            self.REQUIRES_HUMAN_REVIEW: 4,
            self.ACCESSIBILITY_ISSUES: 4,
            self.HIGH_COGNITIVE_LOAD: 3,
            self.LOW_CONFIDENCE: 3,
            self.PROCESSING_TIMEOUT: 2,
            self.PERFORMANCE_WARNING: 1,
            self.SATISFACTORY_QUALITY: 0,
            self.GOOD_QUALITY: 0,
            self.EXCEPTIONAL_QUALITY: 0,
        }
        return priority_map.get(self, 0)


# ============================================================================
# EXPERT IMPROVEMENT 3: TYPED DATA STRUCTURES WITH VALIDATION
# ============================================================================


@dataclass
class ImageData:
    """Enhanced image data structure Î¼Îµ comprehensive metadata"""

    filename: str
    format: str
    size_bytes: int
    dimensions: tuple[int, int]
    mode: str
    has_transparency: bool = False
    color_channels: int = 3
    dpi: Optional[tuple[int, int]] = None
    metadata: Dict[str, Any] = field(default_factory=dict)
    processing_notes: List[str] = field(default_factory=list)

    def validate(self) -> bool:
        """Validate image data Î¼Îµ constants"""
        return (
            self.size_bytes > 0
            and self.dimensions[0] >= ValidationConstants.MIN_IMAGE_DIMENSIONS[0]
            and self.dimensions[1] >= ValidationConstants.MIN_IMAGE_DIMENSIONS[1]
            and self.dimensions[0] <= ValidationConstants.MAX_IMAGE_DIMENSIONS[0]
            and self.dimensions[1] <= ValidationConstants.MAX_IMAGE_DIMENSIONS[1]
            and ValidationConstants.MIN_ASPECT_RATIO
            <= (self.dimensions[0] / self.dimensions[1])
            <= ValidationConstants.MAX_ASPECT_RATIO
        )

    def get_aspect_ratio(self) -> float:
        """Calculate aspect ratio"""
        return (
            self.dimensions[0] / self.dimensions[1] if self.dimensions[1] > 0 else 0.0
        )

    def get_size_mb(self) -> float:
        """Get size in MB"""
        return self.size_bytes / (1024 * 1024)


class MedicalTerm(TypedDict):
    """Medical term structure Î¼Îµ enhanced validation"""

    english_term: str
    greek_term: str
    category: str
    difficulty_level: str
    clinical_relevance: str
    confidence: float
    context: NotRequired[str]
    synonyms: NotRequired[List[str]]
    related_terms: NotRequired[List[str]]
    educational_level: NotRequired[str]


class BloomAnalysis(TypedDict):
    """Bloom's Taxonomy analysis Î¼Îµ comprehensive structure"""

    levels: Dict[str, float]
    dominant_level: str
    complexity_score: float
    educational_value: float
    cognitive_demand: str
    recommendations: List[str]
    confidence: float
    metadata: NotRequired[Dict[str, Any]]


class CognitiveLoadAnalysis(TypedDict):
    """Cognitive Load Theory analysis Î¼Îµ detailed metrics"""

    intrinsic_load: float
    extraneous_load: float
    germane_load: float
    total_load: float
    load_level: str
    effectiveness: float
    recommendations: List[str]
    load_factors: NotRequired[Dict[str, float]]
    optimization_suggestions: NotRequired[List[str]]


class AccessibilityAnalysis(TypedDict):
    """WCAG accessibility analysis Î¼Îµ compliance tracking"""

    wcag_level: str
    compliance_score: float
    contrast_ratio: NotRequired[float]
    text_readability: NotRequired[float]
    color_accessibility: NotRequired[float]
    structure_clarity: NotRequired[float]
    recommendations: List[str]
    violations: NotRequired[List[str]]
    improvements: NotRequired[List[str]]


class VisualAnalysis(TypedDict):
    """Visual analysis structure Î¼Îµ comprehensive metrics"""

    medical_relevance_score: float
    educational_clarity: float
    complexity_level: str
    visual_features: Dict[str, Any]
    clip_features: NotRequired[Dict[str, Any]]
    ai2d_features: NotRequired[Dict[str, Any]]
    quality_metrics: Dict[str, float]
    recommendations: List[str]


class AgentResult(TypedDict):
    """Enhanced agent result structure Î¼Îµ performance tracking"""

    agent_name: str
    success: bool
    status: AgentStatus
    assessment: Dict[str, Any]
    confidence: float
    processing_time: float
    memory_usage: NotRequired[float]
    error_message: NotRequired[str]
    warnings: NotRequired[List[str]]
    metadata: Dict[str, Any]
    quality_flags: List[QualityFlag]
    performance_metrics: NotRequired[Dict[str, Any]]
    retry_count: NotRequired[int]
    cache_hit: NotRequired[bool]


class ErrorInfo(TypedDict):
    """Comprehensive error information structure"""

    error_id: str
    severity: ErrorSeverity
    message: str
    agent_name: NotRequired[str]
    stage: NotRequired[AssessmentStage]
    timestamp: datetime
    stack_trace: NotRequired[str]
    recovery_suggestions: NotRequired[List[str]]
    context: NotRequired[Dict[str, Any]]


class ValidationCheckpoint(TypedDict):
    """Enhanced validation checkpoint Î¼Îµ automated checks"""

    checkpoint_id: str
    stage: AssessmentStage
    timestamp: datetime
    requires_human_validation: bool
    validation_criteria: List[str]
    auto_validation_passed: bool
    validation_results: Dict[str, bool]
    confidence_score: float
    quality_flags: List[QualityFlag]
    recommendations: NotRequired[List[str]]


# ============================================================================
# EXPERT IMPROVEMENT 4: MAIN STATE DEFINITION WITH COMPREHENSIVE STRUCTURE
# ============================================================================


class MedAssessmentState(TypedDict):
    """
    Expert-level comprehensive state definition Î³Î¹Î± medical image assessment

    EXPERT IMPROVEMENTS APPLIED:
    - âœ… Comprehensive typing Î¼Îµ NotRequired Î³Î¹Î± optional fields
    - âœ… Logical section organization Î³Î¹Î± better maintainability
    - âœ… Enhanced metadata tracking Î³Î¹Î± debugging ÎºÎ±Î¹ optimization
    - âœ… Quality assurance integration Î¼Îµ automated flagging
    - âœ… Performance monitoring Î¼Îµ detailed metrics
    """

    # ========================================================================
    # CORE IDENTIFICATION AND METADATA
    # ========================================================================
    session_id: str
    workflow_id: str
    user_id: NotRequired[str]
    created_at: datetime

    # ========================================================================
    # INPUT DATA AND PROCESSING
    # ========================================================================
    image_data: ImageData
    extracted_text: str
    processing_metadata: Dict[str, Any]

    # Raw processing results
    ocr_results: NotRequired[Dict[str, Any]]
    preprocessing_results: NotRequired[Dict[str, Any]]
    feature_extraction_results: NotRequired[Dict[str, Any]]

    # ========================================================================
    # ENHANCED ASSESSMENT RESULTS Î±Ï€ÏŒ EACH AGENT
    # ========================================================================
    medical_terms_analysis: NotRequired[Dict[str, Any]]
    bloom_analysis: NotRequired[BloomAnalysis]
    cognitive_load_analysis: NotRequired[CognitiveLoadAnalysis]
    accessibility_analysis: NotRequired[AccessibilityAnalysis]
    visual_analysis: NotRequired[VisualAnalysis]
    ai2d_analysis: NotRequired[Dict[str, Any]]

    # ========================================================================
    # AGENT EXECUTION TRACKING
    # ========================================================================
    agent_results: Dict[str, AgentResult]
    agent_execution_times: Dict[str, float]
    agent_status: Dict[str, AgentStatus]
    agent_dependencies: NotRequired[Dict[str, List[str]]]

    # ========================================================================
    # PERFORMANCE MONITORING
    # ========================================================================
    cache_hits: Dict[str, bool]
    cache_performance: NotRequired[Dict[str, Any]]
    error_recovery_attempts: Dict[str, int]
    performance_metrics: Dict[str, Any]
    memory_usage: NotRequired[Dict[str, float]]

    # ========================================================================
    # QUALITY ASSURANCE AND VALIDATION
    # ========================================================================
    confidence_scores: Dict[str, float]
    validation_required: bool
    human_review_feedback: NotRequired[Dict[str, Any]]
    quality_flags: List[QualityFlag]
    validation_checkpoints: NotRequired[Dict[str, bool]]

    # ========================================================================
    # WORKFLOW CONTROL AND STATE MANAGEMENT
    # ========================================================================
    current_stage: AssessmentStage
    completed_stages: List[AssessmentStage]
    workflow_status: str
    start_time: datetime
    last_updated: datetime
    total_processing_time: NotRequired[float]

    # Workflow configuration
    workflow_config: NotRequired[Dict[str, Any]]
    parallel_execution_enabled: bool
    checkpoint_data: NotRequired[Dict[str, Any]]

    # ========================================================================
    # ENHANCED SYNTHESIS AND RESULTS
    # ========================================================================
    final_assessment: NotRequired[Dict[str, Any]]
    overall_score: NotRequired[float]
    overall_confidence: NotRequired[float]
    recommendations: NotRequired[List[str]]
    educational_insights: NotRequired[Dict[str, Any]]

    # Comparative analysis
    benchmark_comparison: NotRequired[Dict[str, Any]]
    improvement_suggestions: NotRequired[List[str]]

    # ========================================================================
    # EXPORT AND REPORTING
    # ========================================================================
    export_data: NotRequired[Dict[str, Any]]
    report_generated: NotRequired[bool]
    export_formats: NotRequired[List[str]]

    # ========================================================================
    # ERROR HANDLING AND RECOVERY
    # ========================================================================
    errors: List[ErrorInfo]
    warnings: List[str]
    debug_info: NotRequired[Dict[str, Any]]
    recovery_data: NotRequired[Dict[str, Any]]


# ============================================================================
# EXPERT IMPROVEMENT 5: VALIDATION DECORATORS AND ERROR HANDLING
# ============================================================================


def validate_state_integrity(func: Callable) -> Callable:
    """Decorator Î³Î¹Î± comprehensive state validation"""

    @wraps(func)
    def wrapper(state: MedAssessmentState, *args, **kwargs) -> Any:
        # Pre-validation
        if not _validate_core_state_fields(state):
            raise ValueError("Core state fields validation failed")

        # Execute function
        result = func(state, *args, **kwargs)

        # Post-validation for state modifications
        if isinstance(result, dict) and "session_id" in result:
            if not _validate_modified_state(result):
                logger.warning("State modification validation failed")

        return result

    return wrapper


def _validate_core_state_fields(state: MedAssessmentState) -> bool:
    """Validate core state fields Î¼Îµ constants"""
    try:
        # Session ID validation (extracted method)
        if not _validate_session_id(state.get("session_id", "")):
            return False

        # Image data validation (extracted method)
        if not _validate_image_data(state.get("image_data")):
            return False

        # Stage validation (extracted method)
        if not _validate_current_stage(state.get("current_stage")):
            return False

        # Error count validation (extracted method)
        if not _validate_error_counts(state):
            return False

        return True
    except Exception as e:
        logger.error(f"State validation error: {e}")
        return False


def _validate_session_id(session_id: str) -> bool:
    """Validate session ID format - EXTRACTED METHOD"""
    return (
        isinstance(session_id, str)
        and ValidationConstants.MIN_SESSION_ID_LENGTH
        <= len(session_id)
        <= ValidationConstants.MAX_SESSION_ID_LENGTH
    )


def _validate_image_data(image_data: Any) -> bool:
    """Validate image data structure - EXTRACTED METHOD"""
    if not isinstance(image_data, dict):
        return False

    required_fields = ["filename", "format", "size_bytes", "dimensions"]
    if not all(field in image_data for field in required_fields):
        return False

    # Use constants Î³Î¹Î± validation
    dimensions = image_data.get("dimensions", (0, 0))
    if not isinstance(dimensions, (list, tuple)) or len(dimensions) != 2:
        return False

    width, height = dimensions
    return (
        width >= ValidationConstants.MIN_IMAGE_DIMENSIONS[0]
        and height >= ValidationConstants.MIN_IMAGE_DIMENSIONS[1]
        and width <= ValidationConstants.MAX_IMAGE_DIMENSIONS[0]
        and height <= ValidationConstants.MAX_IMAGE_DIMENSIONS[1]
    )


def _validate_current_stage(current_stage: Any) -> bool:
    """Validate current stage - EXTRACTED METHOD"""
    if isinstance(current_stage, str):
        try:
            AssessmentStage(current_stage)
            return True
        except ValueError:
            return False
    elif isinstance(current_stage, AssessmentStage):
        return True
    return False


def _validate_error_counts(state: MedAssessmentState) -> bool:
    """Validate error and warning counts - EXTRACTED METHOD"""
    errors = state.get("errors", [])
    warnings = state.get("warnings", [])

    return (
        len(errors) <= ValidationConstants.MAX_ERROR_COUNT
        and len(warnings) <= ValidationConstants.MAX_WARNING_COUNT
    )


def _validate_modified_state(state: Dict[str, Any]) -> bool:
    """Validate state after modifications"""
    # Check for required fields after modification
    required_fields = ["session_id", "workflow_id", "current_stage"]
    return all(field in state for field in required_fields)


# ============================================================================
# EXPERT IMPROVEMENT 6: STATE MANAGEMENT UTILITIES WITH EXTRACTED METHODS
# ============================================================================


def create_initial_state(
    session_id: str,
    image_data: ImageData,
    extracted_text: str = "",
    workflow_config: Optional[Dict[str, Any]] = None,
) -> MedAssessmentState:
    """Create initial assessment state Î¼Îµ comprehensive setup"""

    current_time = datetime.now()
    workflow_id = f"workflow_{uuid.uuid4().hex[:8]}"

    # Create initial state structure (extracted method)
    initial_state = _create_base_state_structure(
        session_id, workflow_id, current_time, image_data, extracted_text
    )

    # Add workflow configuration (extracted method)
    initial_state = _add_workflow_configuration(initial_state, workflow_config)

    # Initialize performance tracking (extracted method)
    initial_state = _initialize_performance_tracking(initial_state)

    # Set initial quality flags (extracted method)
    initial_state = _set_initial_quality_flags(initial_state)

    logger.info(f"Initial state created Î³Î¹Î± session {session_id}")
    return initial_state


def _create_base_state_structure(
    session_id: str,
    workflow_id: str,
    current_time: datetime,
    image_data: ImageData,
    extracted_text: str,
) -> MedAssessmentState:
    """Create base state structure - EXTRACTED METHOD"""
    return MedAssessmentState(
        # Core identification
        session_id=session_id,
        workflow_id=workflow_id,
        created_at=current_time,
        # Input data
        image_data=image_data,
        extracted_text=extracted_text,
        processing_metadata={},
        # Agent tracking
        agent_results={},
        agent_execution_times={},
        agent_status={},
        # Performance monitoring
        cache_hits={},
        error_recovery_attempts={},
        performance_metrics={},
        # Quality assurance
        confidence_scores={},
        validation_required=False,
        quality_flags=[],
        # Workflow control
        current_stage=AssessmentStage.INITIALIZATION,
        completed_stages=[],
        workflow_status="initialized",
        start_time=current_time,
        last_updated=current_time,
        parallel_execution_enabled=True,
        # Error handling
        errors=[],
        warnings=[],
    )


def _add_workflow_configuration(
    state: MedAssessmentState, workflow_config: Optional[Dict[str, Any]]
) -> MedAssessmentState:
    """Add workflow configuration to state - EXTRACTED METHOD"""
    if workflow_config:
        state["workflow_config"] = workflow_config
        state["parallel_execution_enabled"] = workflow_config.get(
            "parallel_execution", True
        )

    return state


def _initialize_performance_tracking(state: MedAssessmentState) -> MedAssessmentState:
    """Initialize performance tracking metrics - EXTRACTED METHOD"""
    state["performance_metrics"] = {
        "initialization_time": 0.0,
        "total_agents_executed": 0,
        "cache_hit_rate": 0.0,
        "memory_efficiency": 0.0,
        "processing_efficiency": 0.0,
    }
    return state


def _set_initial_quality_flags(state: MedAssessmentState) -> MedAssessmentState:
    """Set initial quality flags based on input - EXTRACTED METHOD"""
    quality_flags = []

    # Check image quality indicators
    if (
        state["image_data"].get_size_mb()
        > ValidationConstants.MEMORY_WARNING_THRESHOLD_MB / 1024
    ):
        quality_flags.append(QualityFlag.PERFORMANCE_WARNING)

    # Check text length
    text_length = len(state["extracted_text"])
    if text_length < ValidationConstants.MIN_TEXT_LENGTH_CHARACTERS:
        quality_flags.append(QualityFlag.REQUIRES_HUMAN_REVIEW)

    state["quality_flags"] = quality_flags
    return state


@validate_state_integrity
def update_state_stage(
    state: MedAssessmentState,
    new_stage: AssessmentStage,
    metadata: Optional[Dict[str, Any]] = None,
) -> MedAssessmentState:
    """Update workflow stage Î¼Îµ validation ÎºÎ±Î¹ tracking"""

    # Validate stage transition (extracted method)
    if not _validate_stage_transition(state["current_stage"], new_stage):
        logger.warning(
            f"Invalid stage transition: {state['current_stage']} -> {new_stage}"
        )

    # Update stage information (extracted method)
    state = _update_stage_information(state, new_stage, metadata)

    # Update progress tracking (extracted method)
    state = _update_progress_tracking(state, new_stage)

    logger.debug(f"Stage updated: {state['current_stage']} -> {new_stage}")
    return state


def _validate_stage_transition(
    current_stage: AssessmentStage, new_stage: AssessmentStage
) -> bool:
    """Validate stage transition logic - EXTRACTED METHOD"""
    # Allow any transition to ERROR stage
    if new_stage == AssessmentStage.ERROR:
        return True

    # Allow any transition Î±Ï€ÏŒ ERROR stage (recovery)
    if current_stage == AssessmentStage.ERROR:
        return True

    # Get ordered stages Î³Î¹Î± validation
    ordered_stages = AssessmentStage.get_ordered_stages()

    try:
        current_index = ordered_stages.index(current_stage)
        new_index = ordered_stages.index(new_stage)

        # Allow forward progression or same stage (re-processing)
        return new_index >= current_index
    except ValueError:
        # If stages not in ordered list, allow transition
        return True


def _update_stage_information(
    state: MedAssessmentState,
    new_stage: AssessmentStage,
    metadata: Optional[Dict[str, Any]],
) -> MedAssessmentState:
    """Update stage information in state - EXTRACTED METHOD"""
    previous_stage = state["current_stage"]

    # Update current stage
    state["current_stage"] = new_stage

    # Add to completed stages if not already present
    if previous_stage not in state["completed_stages"]:
        state["completed_stages"].append(previous_stage)

    # Update timestamps
    state["last_updated"] = datetime.now()

    # Add metadata if provided
    if metadata:
        if "processing_metadata" not in state:
            state["processing_metadata"] = {}
        state["processing_metadata"][f"stage_{new_stage.value}"] = metadata

    return state


def _update_progress_tracking(
    state: MedAssessmentState, new_stage: AssessmentStage
) -> MedAssessmentState:
    """Update progress tracking metrics - EXTRACTED METHOD"""
    progress_percentage = new_stage.get_progress_percentage()

    # Update workflow status based on stage
    stage_status_map = {
        AssessmentStage.INITIALIZATION: "starting",
        AssessmentStage.PREPROCESSING: "processing",
        AssessmentStage.FEATURE_EXTRACTION: "analyzing",
        AssessmentStage.MEDICAL_TERMS: "evaluating_terms",
        AssessmentStage.BLOOM_TAXONOMY: "assessing_bloom",
        AssessmentStage.COGNITIVE_LOAD: "analyzing_load",
        AssessmentStage.ACCESSIBILITY: "checking_accessibility",
        AssessmentStage.VISUAL_ANALYSIS: "analyzing_visuals",
        AssessmentStage.SYNTHESIS: "synthesizing",
        AssessmentStage.COMPLETED: "completed",
        AssessmentStage.ERROR: "error",
    }

    state["workflow_status"] = stage_status_map.get(new_stage, "processing")

    # Update performance metrics
    if "performance_metrics" in state:
        state["performance_metrics"]["progress_percentage"] = progress_percentage
        state["performance_metrics"]["current_stage"] = new_stage.value

    return state


@validate_state_integrity
def add_agent_result(
    state: MedAssessmentState, agent_result: AgentResult
) -> MedAssessmentState:
    """Add agent result Î¼Îµ comprehensive tracking"""

    agent_name = agent_result["agent_name"]

    # Store agent result (extracted method)
    state = _store_agent_result(state, agent_name, agent_result)

    # Update performance metrics (extracted method)
    state = _update_agent_performance_metrics(state, agent_result)

    # Update quality flags (extracted method)
    state = _update_quality_flags_from_result(state, agent_result)

    # Check validation requirements (extracted method)
    state = _check_validation_requirements(state, agent_result)

    logger.debug(
        f"Agent result added: {agent_name} (success: {agent_result['success']})"
    )
    return state


def _store_agent_result(
    state: MedAssessmentState, agent_name: str, agent_result: AgentResult
) -> MedAssessmentState:
    """Store agent result in state - EXTRACTED METHOD"""
    state["agent_results"][agent_name] = agent_result
    state["agent_execution_times"][agent_name] = agent_result["processing_time"]
    state["agent_status"][agent_name] = agent_result["status"]
    state["confidence_scores"][agent_name] = agent_result["confidence"]

    # Track cache performance
    if "cache_hit" in agent_result:
        state["cache_hits"][agent_name] = agent_result["cache_hit"]

    return state


def _update_agent_performance_metrics(
    state: MedAssessmentState, agent_result: AgentResult
) -> MedAssessmentState:
    """Update performance metrics from agent result - EXTRACTED METHOD"""
    performance_metrics = state.get("performance_metrics", {})

    # Update total agents executed
    performance_metrics["total_agents_executed"] = (
        performance_metrics.get("total_agents_executed", 0) + 1
    )

    # Update cache hit rate
    total_cache_checks = len(state["cache_hits"])
    if total_cache_checks > 0:
        cache_hits = sum(1 for hit in state["cache_hits"].values() if hit)
        performance_metrics["cache_hit_rate"] = cache_hits / total_cache_checks

    # Update processing efficiency
    processing_time = agent_result["processing_time"]
    if processing_time <= QualityMetrics.PROCESSING_TIME_EXCELLENT:
        performance_metrics["processing_efficiency"] = (
            performance_metrics.get("processing_efficiency", 0.0) + 0.2
        )
    elif processing_time <= QualityMetrics.PROCESSING_TIME_GOOD:
        performance_metrics["processing_efficiency"] = (
            performance_metrics.get("processing_efficiency", 0.0) + 0.1
        )

    # Update memory efficiency if available
    if "memory_usage" in agent_result and agent_result["memory_usage"]:
        memory_mb = agent_result["memory_usage"]
        if memory_mb < ValidationConstants.MEMORY_WARNING_THRESHOLD_MB:
            performance_metrics["memory_efficiency"] = (
                performance_metrics.get("memory_efficiency", 0.0) + 0.1
            )

    state["performance_metrics"] = performance_metrics
    return state


def _update_quality_flags_from_result(
    state: MedAssessmentState, agent_result: AgentResult
) -> MedAssessmentState:
    """Update quality flags based on agent result - EXTRACTED METHOD"""
    quality_flags = state.get("quality_flags", [])

    # Add flags Î±Ï€ÏŒ agent result
    if "quality_flags" in agent_result:
        for flag in agent_result["quality_flags"]:
            if flag not in quality_flags:
                quality_flags.append(flag)

    # Add performance-based flags
    processing_time = agent_result["processing_time"]
    confidence = agent_result["confidence"]

    if processing_time > ValidationConstants.WARNING_PROCESSING_TIME_SECONDS:
        if QualityFlag.PERFORMANCE_WARNING not in quality_flags:
            quality_flags.append(QualityFlag.PERFORMANCE_WARNING)

    if confidence < ValidationConstants.LOW_CONFIDENCE_THRESHOLD:
        if QualityFlag.LOW_CONFIDENCE not in quality_flags:
            quality_flags.append(QualityFlag.LOW_CONFIDENCE)

    if not agent_result["success"]:
        if QualityFlag.REQUIRES_HUMAN_REVIEW not in quality_flags:
            quality_flags.append(QualityFlag.REQUIRES_HUMAN_REVIEW)

    # Sort flags by priority
    quality_flags.sort(
        key=lambda flag: (
            flag.get_priority_level() if hasattr(flag, "get_priority_level") else 0
        ),
        reverse=True,
    )

    state["quality_flags"] = quality_flags
    return state


def _check_validation_requirements(
    state: MedAssessmentState, agent_result: AgentResult
) -> MedAssessmentState:
    """Check if validation is required based on result - EXTRACTED METHOD"""
    # Check confidence threshold
    if agent_result["confidence"] < ValidationConstants.MEDIUM_CONFIDENCE_THRESHOLD:
        state["validation_required"] = True

    # Check for critical quality flags
    critical_flags = [QualityFlag.POOR_QUALITY, QualityFlag.ACCESSIBILITY_ISSUES]
    if any(flag in agent_result.get("quality_flags", []) for flag in critical_flags):
        state["validation_required"] = True

    # Check for agent failure
    if not agent_result["success"]:
        state["validation_required"] = True

    return state


@validate_state_integrity
def add_error(state: MedAssessmentState, error_info: ErrorInfo) -> MedAssessmentState:
    """Add error information Î¼Îµ comprehensive tracking"""

    # Add error to list (extracted method)
    state = _add_error_to_state(state, error_info)

    # Update error recovery tracking (extracted method)
    state = _update_error_recovery_tracking(state, error_info)

    # Update quality flags Î³Î¹Î± errors (extracted method)
    state = _update_quality_flags_for_error(state, error_info)

    # Check if critical error requires immediate attention (extracted method)
    state = _check_critical_error_response(state, error_info)

    logger.error(
        f"Error added: {error_info['message']} (severity: {error_info['severity']})"
    )
    return state


def _add_error_to_state(
    state: MedAssessmentState, error_info: ErrorInfo
) -> MedAssessmentState:
    """Add error to state errors list - EXTRACTED METHOD"""
    errors = state.get("errors", [])
    errors.append(error_info)

    # Limit error count to prevent memory issues
    if len(errors) > ValidationConstants.MAX_ERROR_COUNT:
        errors = errors[-ValidationConstants.MAX_ERROR_COUNT :]
        logger.warning(
            f"Error list truncated to {ValidationConstants.MAX_ERROR_COUNT} items"
        )

    state["errors"] = errors
    return state


def _update_error_recovery_tracking(
    state: MedAssessmentState, error_info: ErrorInfo
) -> MedAssessmentState:
    """Update error recovery attempt tracking - EXTRACTED METHOD"""
    agent_name = error_info.get("agent_name", "unknown")

    if agent_name in state["error_recovery_attempts"]:
        state["error_recovery_attempts"][agent_name] += 1
    else:
        state["error_recovery_attempts"][agent_name] = 1

    return state


def _update_quality_flags_for_error(
    state: MedAssessmentState, error_info: ErrorInfo
) -> MedAssessmentState:
    """Update quality flags based on error severity - EXTRACTED METHOD"""
    quality_flags = state.get("quality_flags", [])

    # Add severity-based flags
    if error_info["severity"] >= ErrorSeverity.HIGH:
        if QualityFlag.REQUIRES_HUMAN_REVIEW not in quality_flags:
            quality_flags.append(QualityFlag.REQUIRES_HUMAN_REVIEW)

    if error_info["severity"] == ErrorSeverity.CRITICAL:
        if QualityFlag.POOR_QUALITY not in quality_flags:
            quality_flags.append(QualityFlag.POOR_QUALITY)

    state["quality_flags"] = quality_flags
    return state


def _check_critical_error_response(
    state: MedAssessmentState, error_info: ErrorInfo
) -> MedAssessmentState:
    """Check if critical error requires immediate response - EXTRACTED METHOD"""
    if error_info["severity"] == ErrorSeverity.CRITICAL:
        state["validation_required"] = True
        state["workflow_status"] = "error_critical"

        # Update current stage to ERROR if not already
        if state["current_stage"] != AssessmentStage.ERROR:
            state["current_stage"] = AssessmentStage.ERROR

    return state


def validate_state(state: MedAssessmentState) -> Dict[str, Any]:
    """Comprehensive state validation Î¼Îµ detailed reporting"""

    validation_results = {"valid": True, "errors": [], "warnings": [], "metrics": {}}

    # Core field validation (extracted method)
    core_validation = _validate_core_fields(state)
    validation_results["errors"].extend(core_validation["errors"])
    validation_results["warnings"].extend(core_validation["warnings"])

    # Agent results validation (extracted method)
    agent_validation = _validate_agent_results(state)
    validation_results["errors"].extend(agent_validation["errors"])
    validation_results["warnings"].extend(agent_validation["warnings"])

    # Performance metrics validation (extracted method)
    performance_validation = _validate_performance_metrics(state)
    validation_results["warnings"].extend(performance_validation["warnings"])

    # Quality flags validation (extracted method)
    quality_validation = _validate_quality_flags(state)
    validation_results["warnings"].extend(quality_validation["warnings"])

    # Set overall validation status
    validation_results["valid"] = len(validation_results["errors"]) == 0

    # Generate validation metrics
    validation_results["metrics"] = _generate_validation_metrics(
        state, validation_results
    )

    return validation_results


def _validate_core_fields(state: MedAssessmentState) -> Dict[str, List[str]]:
    """Validate core state fields - EXTRACTED METHOD"""
    errors = []
    warnings = []

    # Required fields check
    required_fields = ["session_id", "workflow_id", "image_data", "current_stage"]
    for field in required_fields:
        if field not in state or not state[field]:
            errors.append(f"Missing required field: {field}")

    # Session ID validation
    if not _validate_session_id(state.get("session_id", "")):
        errors.append("Invalid session_id format")

    # Image data validation
    if not _validate_image_data(state.get("image_data")):
        errors.append("Invalid image_data structure")

    # Stage validation
    if not _validate_current_stage(state.get("current_stage")):
        errors.append("Invalid current_stage value")

    # Timestamp validation
    start_time = state.get("start_time")
    last_updated = state.get("last_updated")
    if start_time and last_updated and last_updated < start_time:
        warnings.append("last_updated is before start_time")

    return {"errors": errors, "warnings": warnings}


def _validate_agent_results(state: MedAssessmentState) -> Dict[str, List[str]]:
    """Validate agent results consistency - EXTRACTED METHOD"""
    errors = []
    warnings = []

    agent_results = state.get("agent_results", {})
    agent_status = state.get("agent_status", {})
    agent_execution_times = state.get("agent_execution_times", {})

    # Check consistency between different agent tracking dictionaries
    for agent_name in agent_results:
        if agent_name not in agent_status:
            warnings.append(f"Agent {agent_name} missing Î±Ï€ÏŒ agent_status")

        if agent_name not in agent_execution_times:
            warnings.append(f"Agent {agent_name} missing Î±Ï€ÏŒ agent_execution_times")

        # Validate agent result structure
        result = agent_results[agent_name]
        if not isinstance(result, dict):
            errors.append(f"Invalid agent result structure Î³Î¹Î± {agent_name}")
            continue

        # Check required agent result fields
        required_result_fields = [
            "agent_name",
            "success",
            "confidence",
            "processing_time",
        ]
        for field in required_result_fields:
            if field not in result:
                errors.append(f"Agent {agent_name} missing required field: {field}")

        # Validate confidence range
        confidence = result.get("confidence", 0)
        if not (0.0 <= confidence <= 1.0):
            errors.append(f"Agent {agent_name} has invalid confidence: {confidence}")

        # Validate processing time
        processing_time = result.get("processing_time", 0)
        if processing_time < 0:
            errors.append(
                f"Agent {agent_name} has negative processing_time: {processing_time}"
            )
        elif processing_time > ValidationConstants.MAX_PROCESSING_TIME_SECONDS:
            warnings.append(
                f"Agent {agent_name} has very long processing_time: {processing_time}s"
            )

    return {"errors": errors, "warnings": warnings}


def _validate_performance_metrics(state: MedAssessmentState) -> Dict[str, List[str]]:
    """Validate performance metrics - EXTRACTED METHOD"""
    warnings = []

    performance_metrics = state.get("performance_metrics", {})

    # Check cache hit rate
    cache_hit_rate = performance_metrics.get("cache_hit_rate", 0)
    if cache_hit_rate < ValidationConstants.LOW_CONFIDENCE_THRESHOLD:
        warnings.append(f"Low cache hit rate: {cache_hit_rate:.2%}")

    # Check memory usage
    memory_usage = state.get("memory_usage", {})
    for component, usage in memory_usage.items():
        if usage > ValidationConstants.MEMORY_WARNING_THRESHOLD_MB:
            warnings.append(f"High memory usage in {component}: {usage}MB")

    # Check total processing time
    total_time = state.get("total_processing_time", 0)
    if total_time > ValidationConstants.MAX_PROCESSING_TIME_SECONDS:
        warnings.append(f"Long total processing time: {total_time}s")

    return {"warnings": warnings}


def _validate_quality_flags(state: MedAssessmentState) -> Dict[str, List[str]]:
    """Validate quality flags consistency - EXTRACTED METHOD"""
    warnings = []

    quality_flags = state.get("quality_flags", [])

    # Check for conflicting quality flags
    quality_levels = [
        QualityFlag.EXCEPTIONAL_QUALITY,
        QualityFlag.GOOD_QUALITY,
        QualityFlag.SATISFACTORY_QUALITY,
        QualityFlag.POOR_QUALITY,
    ]

    present_quality_levels = [flag for flag in quality_flags if flag in quality_levels]
    if len(present_quality_levels) > 1:
        warnings.append(f"Multiple quality levels present: {present_quality_levels}")

    # Check Î³Î¹Î± high-priority flags
    high_priority_flags = [
        flag
        for flag in quality_flags
        if hasattr(flag, "get_priority_level") and flag.get_priority_level() >= 4
    ]
    if high_priority_flags and not state.get("validation_required", False):
        warnings.append(
            "High-priority quality flags present but validation not required"
        )

    return {"warnings": warnings}


def _generate_validation_metrics(
    state: MedAssessmentState, validation_results: Dict[str, Any]
) -> Dict[str, Any]:
    """Generate validation metrics - EXTRACTED METHOD"""
    return {
        "total_errors": len(validation_results["errors"]),
        "total_warnings": len(validation_results["warnings"]),
        "agent_count": len(state.get("agent_results", {})),
        "completed_stages": len(state.get("completed_stages", [])),
        "quality_flags_count": len(state.get("quality_flags", [])),
        "validation_required": state.get("validation_required", False),
        "current_stage": state.get("current_stage", "unknown"),
        "progress_percentage": (
            state.get(
                "current_stage", AssessmentStage.INITIALIZATION
            ).get_progress_percentage()
            if hasattr(state.get("current_stage"), "get_progress_percentage")
            else 0.0
        ),
    }


def get_state_summary(state: MedAssessmentState) -> str:
    """Generate comprehensive state summary Î¼Îµ improved formatting"""

    # Header section (extracted method)
    header = _create_summary_header(state)

    # Progress section (extracted method)
    progress = _create_summary_progress(state)

    # Agent results section (extracted method)
    agents = _create_summary_agents(state)

    # Quality section (extracted method)
    quality = _create_summary_quality(state)

    # Performance section (extracted method)
    performance = _create_summary_performance(state)

    return "\n".join([header, progress, agents, quality, performance])


def _create_summary_header(state: MedAssessmentState) -> str:
    """Create summary header section - EXTRACTED METHOD"""
    session_id = state.get("session_id", "unknown")
    workflow_status = state.get("workflow_status", "unknown")

    return f"""ðŸ“Š Assessment Summary Î³Î¹Î± Session: {session_id}
Status: {workflow_status.upper()}"""


def _create_summary_progress(state: MedAssessmentState) -> str:
    """Create summary progress section - EXTRACTED METHOD"""
    current_stage = state.get("current_stage", AssessmentStage.INITIALIZATION)
    completed_stages = state.get("completed_stages", [])

    progress_percentage = (
        current_stage.get_progress_percentage()
        if hasattr(current_stage, "get_progress_percentage")
        else 0.0
    )

    return f"""ðŸ”„ Progress: {progress_percentage:.1f}%
Current Stage: {current_stage.value if hasattr(current_stage, 'value') else str(current_stage)}
Completed Stages: {len(completed_stages)}"""


def _create_summary_agents(state: MedAssessmentState) -> str:
    """Create summary agents section - EXTRACTED METHOD"""
    agent_results = state.get("agent_results", {})

    if not agent_results:
        return "ðŸ¤– Agents: No agents executed yet"

    successful_agents = sum(
        1 for result in agent_results.values() if result.get("success", False)
    )
    total_agents = len(agent_results)

    return f"""ðŸ¤– Agents: {successful_agents}/{total_agents} successful
Average Confidence: {sum(result.get('confidence', 0) for result in agent_results.values()) / total_agents:.2f}"""


def _create_summary_quality(state: MedAssessmentState) -> str:
    """Create summary quality section - EXTRACTED METHOD"""
    quality_flags = state.get("quality_flags", [])
    validation_required = state.get("validation_required", False)

    if not quality_flags:
        quality_status = "âœ… No quality issues"
    else:
        high_priority_count = sum(
            1
            for flag in quality_flags
            if hasattr(flag, "get_priority_level") and flag.get_priority_level() >= 3
        )
        quality_status = f"âš ï¸ {len(quality_flags)} quality flags ({high_priority_count} high priority)"

    validation_status = "ðŸ” Required" if validation_required else "âœ… Not required"

    return f"""ðŸŽ¯ Quality: {quality_status}
Validation: {validation_status}"""


def _create_summary_performance(state: MedAssessmentState) -> str:
    """Create summary performance section - EXTRACTED METHOD"""
    performance_metrics = state.get("performance_metrics", {})
    cache_hits = state.get("cache_hits", {})

    cache_hit_rate = performance_metrics.get("cache_hit_rate", 0.0)
    total_processing_time = state.get("total_processing_time", 0.0)

    return f"""âš¡ Performance:
Cache Hit Rate: {cache_hit_rate:.1%}
Total Processing Time: {total_processing_time:.1f}s"""


def export_state_for_recovery(state: MedAssessmentState) -> Dict[str, Any]:
    """Export state Î³Î¹Î± recovery purposes Î¼Îµ comprehensive data"""

    export_data = {
        "metadata": _create_export_metadata(state),
        "core_state": _create_export_core_state(state),
        "agent_results": _create_export_agent_results(state),
        "performance_data": _create_export_performance_data(state),
        "quality_data": _create_export_quality_data(state),
        "export_timestamp": datetime.now().isoformat(),
    }

    return export_data


def _create_export_metadata(state: MedAssessmentState) -> Dict[str, Any]:
    """Create export metadata - EXTRACTED METHOD"""
    return {
        "session_id": state.get("session_id"),
        "workflow_id": state.get("workflow_id"),
        "current_stage": (
            state.get("current_stage").value
            if hasattr(state.get("current_stage"), "value")
            else str(state.get("current_stage"))
        ),
        "workflow_status": state.get("workflow_status"),
        "created_at": (
            state.get("created_at").isoformat() if state.get("created_at") else None
        ),
        "last_updated": (
            state.get("last_updated").isoformat() if state.get("last_updated") else None
        ),
    }


def _create_export_core_state(state: MedAssessmentState) -> Dict[str, Any]:
    """Create export core state - EXTRACTED METHOD"""
    return {
        "image_data": state.get("image_data"),
        "extracted_text": state.get("extracted_text"),
        "completed_stages": [
            stage.value if hasattr(stage, "value") else str(stage)
            for stage in state.get("completed_stages", [])
        ],
        "processing_metadata": state.get("processing_metadata", {}),
    }


def _create_export_agent_results(state: MedAssessmentState) -> Dict[str, Any]:
    """Create export agent results - EXTRACTED METHOD"""
    return {
        "agent_results": state.get("agent_results", {}),
        "agent_execution_times": state.get("agent_execution_times", {}),
        "agent_status": {
            k: v.value if hasattr(v, "value") else str(v)
            for k, v in state.get("agent_status", {}).items()
        },
        "confidence_scores": state.get("confidence_scores", {}),
    }


def _create_export_performance_data(state: MedAssessmentState) -> Dict[str, Any]:
    """Create export performance data - EXTRACTED METHOD"""
    return {
        "performance_metrics": state.get("performance_metrics", {}),
        "cache_hits": state.get("cache_hits", {}),
        "error_recovery_attempts": state.get("error_recovery_attempts", {}),
        "memory_usage": state.get("memory_usage", {}),
        "total_processing_time": state.get("total_processing_time"),
    }


def _create_export_quality_data(state: MedAssessmentState) -> Dict[str, Any]:
    """Create export quality data - EXTRACTED METHOD"""
    return {
        "quality_flags": [
            flag.value if hasattr(flag, "value") else str(flag)
            for flag in state.get("quality_flags", [])
        ],
        "validation_required": state.get("validation_required", False),
        "errors": state.get("errors", []),
        "warnings": state.get("warnings", []),
    }


def restore_state_from_recovery(recovery_data: Dict[str, Any]) -> MedAssessmentState:
    """Restore state Î±Ï€ÏŒ recovery data Î¼Îµ validation"""

    # Validate recovery data format (extracted method)
    if not _validate_recovery_data(recovery_data):
        raise ValueError("Invalid recovery data format")

    # Create base state Î±Ï€ÏŒ metadata (extracted method)
    state = _create_state_from_metadata(recovery_data["metadata"])

    # Restore core state (extracted method)
    state = _restore_core_state_data(state, recovery_data["core_state"])

    # Restore agent results (extracted method)
    state = _restore_agent_results_data(state, recovery_data["agent_results"])

    # Restore performance data (extracted method)
    state = _restore_performance_data(state, recovery_data["performance_data"])

    # Restore quality data (extracted method)
    state = _restore_quality_data(state, recovery_data["quality_data"])

    logger.info(f"State restored Î±Ï€ÏŒ recovery data Î³Î¹Î± session {state['session_id']}")
    return state


def _validate_recovery_data(recovery_data: Dict[str, Any]) -> bool:
    """Validate recovery data structure - EXTRACTED METHOD"""
    required_sections = [
        "metadata",
        "core_state",
        "agent_results",
        "performance_data",
        "quality_data",
    ]
    return all(section in recovery_data for section in required_sections)


def _create_state_from_metadata(metadata: Dict[str, Any]) -> MedAssessmentState:
    """Create base state Î±Ï€ÏŒ metadata - EXTRACTED METHOD"""
    # Convert string timestamps back to datetime objects
    created_at = (
        datetime.fromisoformat(metadata["created_at"])
        if metadata.get("created_at")
        else datetime.now()
    )
    last_updated = (
        datetime.fromisoformat(metadata["last_updated"])
        if metadata.get("last_updated")
        else datetime.now()
    )

    # Convert stage string back to enum
    current_stage = (
        AssessmentStage(metadata["current_stage"])
        if metadata.get("current_stage")
        else AssessmentStage.INITIALIZATION
    )

    return MedAssessmentState(
        session_id=metadata["session_id"],
        workflow_id=metadata["workflow_id"],
        created_at=created_at,
        current_stage=current_stage,
        workflow_status=metadata.get("workflow_status", "restored"),
        last_updated=last_updated,
        # Initialize required fields Ï€Î¿Ï… will be populated
        image_data={},
        extracted_text="",
        processing_metadata={},
        agent_results={},
        agent_execution_times={},
        agent_status={},
        cache_hits={},
        error_recovery_attempts={},
        performance_metrics={},
        confidence_scores={},
        validation_required=False,
        quality_flags=[],
        completed_stages=[],
        start_time=created_at,
        parallel_execution_enabled=True,
        errors=[],
        warnings=[],
    )


def _restore_core_state_data(
    state: MedAssessmentState, core_data: Dict[str, Any]
) -> MedAssessmentState:
    """Restore core state data - EXTRACTED METHOD"""
    state["image_data"] = core_data.get("image_data", {})
    state["extracted_text"] = core_data.get("extracted_text", "")
    state["processing_metadata"] = core_data.get("processing_metadata", {})

    # Convert completed stages back to enums
    completed_stages = []
    for stage_str in core_data.get("completed_stages", []):
        try:
            completed_stages.append(AssessmentStage(stage_str))
        except ValueError:
            logger.warning(f"Unknown stage in recovery data: {stage_str}")

    state["completed_stages"] = completed_stages
    return state


def _restore_agent_results_data(
    state: MedAssessmentState, agent_data: Dict[str, Any]
) -> MedAssessmentState:
    """Restore agent results data - EXTRACTED METHOD"""
    state["agent_results"] = agent_data.get("agent_results", {})
    state["agent_execution_times"] = agent_data.get("agent_execution_times", {})
    state["confidence_scores"] = agent_data.get("confidence_scores", {})

    # Convert agent status strings back to enums
    agent_status = {}
    for agent_name, status_str in agent_data.get("agent_status", {}).items():
        try:
            agent_status[agent_name] = AgentStatus(status_str)
        except ValueError:
            logger.warning(f"Unknown agent status in recovery data: {status_str}")
            agent_status[agent_name] = AgentStatus.PENDING

    state["agent_status"] = agent_status
    return state


def _restore_performance_data(
    state: MedAssessmentState, performance_data: Dict[str, Any]
) -> MedAssessmentState:
    """Restore performance data - EXTRACTED METHOD"""
    state["performance_metrics"] = performance_data.get("performance_metrics", {})
    state["cache_hits"] = performance_data.get("cache_hits", {})
    state["error_recovery_attempts"] = performance_data.get(
        "error_recovery_attempts", {}
    )
    state["memory_usage"] = performance_data.get("memory_usage", {})
    state["total_processing_time"] = performance_data.get("total_processing_time")
    return state


def _restore_quality_data(
    state: MedAssessmentState, quality_data: Dict[str, Any]
) -> MedAssessmentState:
    """Restore quality data - EXTRACTED METHOD"""
    # Convert quality flag strings back to enums
    quality_flags = []
    for flag_str in quality_data.get("quality_flags", []):
        try:
            quality_flags.append(QualityFlag(flag_str))
        except ValueError:
            logger.warning(f"Unknown quality flag in recovery data: {flag_str}")

    state["quality_flags"] = quality_flags
    state["validation_required"] = quality_data.get("validation_required", False)
    state["errors"] = quality_data.get("errors", [])
    state["warnings"] = quality_data.get("warnings", [])
    return state


# ============================================================================
# EXPERT IMPROVEMENT 7: COMPREHENSIVE EXPORTS
# ============================================================================

__all__ = [
    # Constants Classes (Expert Improvement)
    "ValidationConstants",
    "QualityMetrics",
    # Enhanced Enums
    "AssessmentStage",
    "AgentStatus",
    "ErrorSeverity",
    "QualityFlag",
    # Data Structures
    "ImageData",
    "MedicalTerm",
    "BloomAnalysis",
    "CognitiveLoadAnalysis",
    "AccessibilityAnalysis",
    "VisualAnalysis",
    "AgentResult",
    "ErrorInfo",
    "ValidationCheckpoint",
    # Main State Definition
    "MedAssessmentState",
    # State Management Functions Î¼Îµ Validation
    "create_initial_state",
    "update_state_stage",
    "add_agent_result",
    "add_error",
    "validate_state",
    "get_state_summary",
    "export_state_for_recovery",
    "restore_state_from_recovery",
    # Validation Decorators (Expert Improvement)
    "validate_state_integrity",
]


# ============================================================================
# EXPERT IMPROVEMENTS SUMMARY
# ============================================================================
"""
ðŸŽ¯ EXPERT-LEVEL IMPROVEMENTS APPLIED TO workflows/state_definitions.py:

âœ… 1. MAGIC NUMBERS ELIMINATION:
   - Created ValidationConstants class Î¼Îµ 25+ centralized constants
   - Created QualityMetrics class Î³Î¹Î± assessment thresholds
   - All hardcoded validation values replaced Î¼Îµ named constants

âœ… 2. FUNCTION COMPLEXITY REDUCTION:
   - Extracted 20+ private methods Î±Ï€ÏŒ complex functions:
     * _validate_session_id(), _validate_image_data(), _validate_current_stage()
     * _create_base_state_structure(), _add_workflow_configuration()
     * _store_agent_result(), _update_agent_performance_metrics()
     * _create_summary_*() methods (5 methods)
     * _create_export_*() methods (5 methods)
     * _restore_*() methods (5 methods)

âœ… 3. DUPLICATE VALIDATION PATTERN ELIMINATION:
   - Centralized validation logic in reusable functions
   - Common validation patterns extracted to helper methods
   - Consistent error handling across all validation points

âœ… 4. ENHANCED TYPE SAFETY:
   - Comprehensive TypedDict usage Î¼Îµ NotRequired Î³Î¹Î± optional fields
   - Proper enum integration Î¼Îµ validation methods
   - Enhanced dataclass structures Î¼Îµ built-in validation

âœ… 

# Finish"""
